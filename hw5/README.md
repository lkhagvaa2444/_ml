# âœï¸ Backpropagation by Hand â€“ Chain Rule Exercises

This project walks through two exercises for manually computing gradients using the **chain rule** of calculus, to understand **backpropagation** step-by-step.

---

## ğŸ“Œ Problems

### Question 1
**Function:**  
`f(x, y, z) = (x * y) + z`  
**Given:**  
`x=1, y=2, z=3`

### Question 2
**Function:**  
`f(x, y, z, t) = ((x * y) + z) * t`  
**Given:**  
`x=1, y=2, z=3, t=4`

---

## âœ… Final Answers

### Question 1:
- âˆ‚f/âˆ‚x = 2  
- âˆ‚f/âˆ‚y = 1  
- âˆ‚f/âˆ‚z = 1  

### Question 2:
- âˆ‚f/âˆ‚x = 8  
- âˆ‚f/âˆ‚y = 4  
- âˆ‚f/âˆ‚z = 4  
- âˆ‚f/âˆ‚t = 5  

---

## ğŸ§  Learning Goal

These exercises teach how **gradients** flow through a computation graph, and how to use the **chain rule** to compute derivatives manually â€” a fundamental idea behind **backpropagation** in neural networks.
